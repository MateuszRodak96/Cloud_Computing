{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Malaria-Infected Cells using Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example Amazon SageMaker image classification algorithm will be used to train on Malaria-Infected cell images.<br>\n",
    "The steps taken in order to achive fully deployed model are:\n",
    "- preparation of the dataset (downloading, resizing, converting to .rec file, uploading to S3)\n",
    "- training model (setting up connection and data channels, choosing training instance, setting up hyperparameters)\n",
    "- deploying model locally \n",
    "Training was performed on 2 different instances to compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is taken from the official NIH Website: https://ceb.nlm.nih.gov/repositories/malaria-datasets. <br>\n",
    "It contains 13775 images of blood cells infected by malaria:\n",
    "<img src=\"images/1.jpg\">\n",
    "And 13779 uninfected ones:\n",
    "<img src=\"images/2.jpg\">\n",
    "Every cell has different shape and colour varying from pink to purple.\n",
    "Malaria-causing parasite Plasmodium visible as dark spot appears in many shapes, positions and sizes.\n",
    "The pictures have different widths and heights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All  images have been cropped to size 224x224 used by many available Image classifiers and to lower file size which be uploaded to S3 - Amazon cloud storage service. <br> Script used to resize images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, sys\n",
    "import urllib.request\n",
    "\n",
    "# path to cell images\n",
    "path = \"...\"\n",
    "dirs = os.listdir( path )\n",
    "\n",
    "def resize():\n",
    "    i = 0\n",
    "    for item in dirs:\n",
    "        if os.path.isfile(path+item):\n",
    "            im = Image.open(path+item)\n",
    "            f, e = os.path.splitext(path+item)\n",
    "            imResize = im.resize((224,224), Image.ANTIALIAS)\n",
    "            imResize.save(\"...\" + str(i) + '.jpg', 'JPEG', quality=90)\n",
    "            i = i + 1\n",
    "\n",
    "resize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepared images were uploaded to S3 bucket. <br> In order to speed up training .rec files were made using MXNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An S3 Bucket Name\n",
    "data_bucket_name='...'\n",
    "\n",
    "# A prefix name inside the S3 bucket containing sub-folders of images (one per label class)\n",
    "dataset_name = '...' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MXNet im2rec.py\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "        \n",
    "download('https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py')\n",
    "\n",
    "# Find im2rec in our environment and set up some other vars in our environemnt\n",
    "base_dir='/tmp'\n",
    "\n",
    "%env BASE_DIR=$base_dir\n",
    "%env S3_DATA_BUCKET_NAME = $data_bucket_name\n",
    "%env DATASET_NAME = $dataset_name\n",
    "\n",
    "\n",
    "suffix='/home/ec2-user/SageMaker/jupyter-notebooks/im2rec.py'\n",
    "\n",
    "im2rec = suffix\n",
    "%env IM2REC=$im2rec\n",
    "\n",
    "\n",
    "# Use the IM2REC script to convert our images into RecordIO files\n",
    "%%bash\n",
    "\n",
    "# Clean up our working dir of existing LST and REC files\n",
    "cd $BASE_DIR\n",
    "rm *.rec\n",
    "rm *.lst\n",
    "\n",
    "# First we need to create two LST files (training and test lists), noting the correct label class for each image\n",
    "# We'll also save the output of the LST files command, since it includes a list of all of our label classes\n",
    "echo \"Creating LST files\"\n",
    "python $IM2REC --list --recursive --pass-through --test-ratio=0.3 --train-ratio=0.7 $DATASET_NAME $DATASET_NAME > ${DATASET_NAME}_classes\n",
    "\n",
    "echo \"Label classes:\"\n",
    "cat ${DATASET_NAME}_classes\n",
    "\n",
    "# Then we create RecordIO files from the LST files\n",
    "echo \"Creating RecordIO files\"\n",
    "python $IM2REC --num-thread=4 ${DATASET_NAME}_train.lst $DATASET_NAME\n",
    "python $IM2REC --num-thread=4 ${DATASET_NAME}_test.lst $DATASET_NAME\n",
    "ls -lh *.rec\n",
    "\n",
    "# Upload our train and test RecordIO files to S3 in the bucket that our sagemaker session is using\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "s3train_path = 's3://{}/{}/train/'.format(bucket, dataset_name)\n",
    "s3validation_path = 's3://{}/{}/validation/'.format(bucket, dataset_name)\n",
    "\n",
    "# Clean up any existing data\n",
    "!aws s3 rm s3://{bucket}/{dataset_name}/train --recursive\n",
    "!aws s3 rm s3://{bucket}/{dataset_name}/validation --recursive\n",
    "\n",
    "# Upload the rec files to the train and validation channels\n",
    "!aws s3 cp /tmp/{dataset_name}_train.rec $s3train_path\n",
    "!aws s3 cp /tmp/{dataset_name}_test.rec $s3validation_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# Set up the linkage and authentication to AWS services\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'image-classification', repo_version=\"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign data channels with RecordIO files SageMaker used for training\n",
    "train_data = sagemaker.session.s3_input(\n",
    "    s3train_path, \n",
    "    distribution='FullyReplicated', \n",
    "    content_type='application/x-recordio', \n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "\n",
    "validation_data = sagemaker.session.s3_input(\n",
    "    s3validation_path, \n",
    "    distribution='FullyReplicated', \n",
    "    content_type='application/x-recordio', \n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train Sagemaker Image Classifier GPU computing instance is required <br>\n",
    "Access to these instances can be obtained by creating case \"Limit Increase\" in AWS Support Center if Free Tier Account is used. <br>\n",
    "P2 instances provide up to 16 NVIDIA K80 GPUs, 64 vCPUs and 732 GiB of host memory, with a combined 192 GB of GPU memory. <br>\n",
    "In this project, at first, P2 Xlarge instance was used. It provide one NVIDIA K80 GPU. <br>\n",
    "Then it was compared with training on P2 8 Xlarge instance, with 8 GPUs.\n",
    "One K80 GPU scores 8.73 teraflops single-precision performance with NVIDIA GPU Boost. \n",
    "Graphic card of my laptop scores 0.79 teraflops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, dataset_name)\n",
    "\n",
    "# Define train instance type and output path\n",
    "image_classifier = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role,\n",
    "    train_instance_count=1, \n",
    "    train_instance_type='ml.p2.xlarge',\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=! ls -l {base_dir}/{dataset_name} | wc -l\n",
    "num_classes=int(num_classes[0]) - 1\n",
    "\n",
    "num_training_samples=! cat {base_dir}/{dataset_name}_train.lst | wc -l\n",
    "num_training_samples = int(num_training_samples[0])\n",
    "\n",
    "# the size of the images we'll be sending for input, the number of training classes we have, etc.\n",
    "base_hyperparameters=dict(\n",
    "    use_pretrained_model=1,\n",
    "    image_shape='3,224,224',\n",
    "    num_classes=num_classes,\n",
    "    num_training_samples=num_training_samples,\n",
    ")\n",
    "\n",
    "# These are hyperparameters we may want to tune, as they can affect the model training success:\n",
    "hyperparameters={\n",
    "    **base_hyperparameters, \n",
    "    **dict(\n",
    "        learning_rate=0.0001,\n",
    "        mini_batch_size=5,\n",
    "        epochs=4,\n",
    "    )\n",
    "}\n",
    "\n",
    "image_classifier.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "now = str(int(time.time()))\n",
    "training_job_name = 'IC-' + dataset_name.replace('_', '-') + '-' + now\n",
    "\n",
    "image_classifier.fit(inputs=data_channels, job_name=training_job_name, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model hyperparameters\n",
    "<img src=\"images/3.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of training process\n",
    "<img src=\"images/4.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of training process\n",
    "<img src=\"images/5.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_instance_type parameter was changed to ml.p2.8xlarge, hyperparameter mini_batch_size had to be changed for more or equal to 8 in order to use all 8 GPUs of training instance.\n",
    "Training process looked like before, but it took less time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/11.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on 8 times more powerfull machine took ~3 times less time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/12a.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and was ~3 times more expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~97% accuracy was achieved<br>\n",
    "Model was saved in S3 bucket as model.tar.gz file.<br>\n",
    "Model can be deployed using AWS machines as it can be seen in Gabe Hollombe tutorial, link in references.<br>\n",
    "I decided to deploy model on my computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model was downloaded from S3 bucket.<br>\n",
    "Model after extraction:\n",
    "<img src=\"images/6.jpg\">\n",
    "In order to deploy model locally MXNet package was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to extracted model and epoch number\n",
    "lenet_model = mx.mod.Module.load('model/image-classification',4)\n",
    "image_l = 224\n",
    "image_w = 224\n",
    "lenet_model.bind(for_training=False, data_shapes=[('data',(1,3,image_l,image_w))],label_shapes=lenet_model._label_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "def predict(name, labels):\n",
    "    # convert [x, y, channels] format of jpg to [bath, channels, x, y] format required by mxnet\n",
    "    img = img=mpimg.imread(name)\n",
    "    img = np.array([img[:,:,0], img[:,:,1], img[:,:,2]])\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # compute the predict probabilities\n",
    "    lenet_model.forward(Batch([mx.nd.array(img)]))\n",
    "    prob = lenet_model.get_outputs()[0].asnumpy()\n",
    "\n",
    "    prob = np.squeeze(prob)\n",
    "    a = np.argsort(prob)[::-1]\n",
    "\n",
    "    for i in a[0:2]:\n",
    "       print('probability=%f, class=%s' %(prob[i], labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '0.jpg'\n",
    "\n",
    "labels = ['parasitized','uninfected']\n",
    "predict(image_path, labels )\n",
    "\n",
    "image = mpimg.imread(image_path)\n",
    "imgplot = plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "<img src=\"images/7.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is much more dangerous to misclassify parasitized blood cell as uninfected one, these errors were found to take a closer look. <br>\n",
    "Some blood cells labeled as parasitized by human and labeled as uninfected by model:\n",
    "<img src=\"images/8.jpg\">\n",
    "Suprising misclasification:\n",
    "<img src=\"images/9.jpg\">\n",
    "Barely visible malaria:\n",
    "<img src=\"images/10.jpg\">\n",
    "In order to reduce false negatives number, threshold should be adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important tutorial used for this project: <br>\n",
    "https://github.com/gabehollombe-aws/jupyter-notebooks/blob/master/DL%20Intro%20Demo%20-%20Sagemaker%20Image%20Classifer%20via%20Transfer%20Learning.ipynb\n",
    "<br>with youtube video<br> https://www.youtube.com/watch?v=KCzgR7eQ3PY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End-to-End Multiclass Image Classification Example:<br>\n",
    "https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/imageclassification_caltech/Image-classification-fulltraining.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
